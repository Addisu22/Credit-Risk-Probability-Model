{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acebf698",
   "metadata": {},
   "source": [
    "# Task-6 Model Deployment and Continuous Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5627c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import load_and_split_data\n",
    "from src.model_utils import tune_and_train\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def main():\n",
    "    X_train, X_test, y_train, y_test = load_and_split_data(\"Data/processed/cleaned_data.csv\", target_col=\"fraudresult\")\n",
    "\n",
    "    if X_train is None:\n",
    "        return\n",
    "\n",
    "    models = {\n",
    "        \"LogisticRegression\": (LogisticRegression(max_iter=1000), {\n",
    "            \"classifier__C\": [0.1, 1.0, 10]\n",
    "        }),\n",
    "        \"RandomForest\": (RandomForestClassifier(random_state=42), {\n",
    "            \"classifier__n_estimators\": [100, 200],\n",
    "            \"classifier__max_depth\": [5, 10]\n",
    "        }),\n",
    "        \"XGBoost\": (XGBClassifier(use_label_encoder=False, eval_metric='logloss'), {\n",
    "            \"classifier__n_estimators\": [100],\n",
    "            \"classifier__max_depth\": [3, 5]\n",
    "        })\n",
    "    }\n",
    "\n",
    "    for name, (model, params) in models.items():\n",
    "        tune_and_train(X_train, y_train, X_test, y_test, model_name=name, model=model, param_grid=params)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
